global:
  storageClass: "ocs-external-storagecluster-ceph-rbd"

# ChRIS automatic admin account
#####################

chris_admin:
  username: fnndsc
  email: dev@babymri.org
  # If no password is set, then a random password is created for you.
  # password:


# Ingress and HTTPS
ingress:
  enabled: true
  className: openshift-default
  annotations:
    cert-manager.io/issuer: letsencrypt
    acme.cert-manager.io/http01-ingress-class: openshift-default
  hosts:
    - host: cube.chrisproject.org
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: cube-chrisproject-org-letsencrypt
      hosts:
        - cube.chrisproject.org


# ChRIS Backend
#####################
cube:
  image:
    repository: ghcr.io/fnndsc/cube
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: "5.1.0"  # see https://github.com/FNNDSC/ChRIS_ultron_backEnd/releases/tag/v5.1.0

  # Use inter-pod affinity as a workaround for using a ReadWriteOnce PersistentVolumeClaim
  enablePodAffinityWorkaround: true

  # Configuration
  #####################
  config:
    # Configuration of the gunicorn WSGI server.
    # ref: https://docs.gunicorn.org/en/stable/settings.html
    GUNICORN_CMD_ARGS: "--workers=8 --timeout=3600"
    # smaller values increases responsiveness at the cost of resource usage and possibly concurrency bugs
    CUBE_CELERY_POLL_INTERVAL: "5.0"
    # HTTP server security settings
    DJANGO_ALLOWED_HOSTS: "*"  # note: * is okay if OpenShift router or k8s igress is validating host header
    DJANGO_CORS_ALLOW_ALL_ORIGINS: "false"
    DJANGO_CORS_ALLOWED_ORIGINS: "https://app.chrisproject.org"
    DJANGO_SECURE_PROXY_SSL_HEADER: "HTTP_X_FORWARDED_PROTO,https"
    DJANGO_USE_X_FORWARDED_HOST: "true"
    # enable LDAP login
    AUTH_LDAP: "false"

  # Since this is the "mother" CUBE, it has nowhere to get plugins from, so plugins must be blank.
  plugins: []

  # The volume is managed by pfcon's subchart, so leave this as "enabled: false"
  storage:
    enabled: false

  # Resources
  #####################
  workerMains:
    ## Resources for the main worker.
    ## It requires a large memory allocation due to an inefficient implementation.
    ## Recommended value is x4 the size of the largest anticipated plugin instance output directory.
    resources:
      requests:
        memory: 11444Mi
        cpu: 3
      limits:
        memory: 11444Mi
        cpu: 3

  workerPeriodic:
    ## Resources for the periodic worker.
    ## Default values should be okay. Memory request may be further reduced to ~400Mi.
    resources:
      requests:
        memory: 1Gi
        cpu: 250m
      limits:
        memory: 1Gi
        cpu: 250m

  server:
    ## resources for the HTTP server (WSGI).
    ## Default values should be okay. About 256Mi of memory is needed per idle worker.
    resources:
      requests:
        memory: 11Gi
        cpu: 3
      limits:
        memory: 11Gi
        cpu: 3

# Database
#####################

# [SUBCHART] PostgreSQL packaged by Bitnami
# https://github.com/bitnami/charts/tree/main/bitnami/postgresql#parameters
postgresql:

  # no reason to change these values
  auth:
    database: "chris"
    username: "chris"

  # one of: [standalone, replication]
  # Replication is supported, see upstream README.md for configuration.
  architecture: standalone

  primary:
    # Primary database instance resource requests
    resources:
      requests:
        memory: 3814Mi
        cpu: 1
      limits:
        memory: 3814Mi
        cpu: 1

    persistence:
      enabled: true
      size: 8Gi

    # Defer control of security configurations to OpenShift
    podSecurityContext:
      enabled: false
    containerSecurityContext:
      enabled: false
  volumePermissions:
    enabled: false
  shmVolume:
    enabled: false

# [SUBCHART] RabbitMQ packaged by Bitnami
# https://github.com/bitnami/charts/tree/main/bitnami/rabbitmq#parameters
rabbitmq:

  # No reason to change these values.
  #
  # Whether or not to set a password for RabbitMQ depends on your threat model.
  # The RabbitMQ service does not receive ingress traffic, the password appears
  # here in values.yaml due to limitations of how Helm charts share variables
  # with subcharts.
  auth:
    username: "chris"
    password: "chris1234"

  resources:
    limits:
      cpu: 1
      memory: 3814Mi
    requests:
      cpu: 1
      memory: 3814Mi

  persistence:
    enabled: true
    size: 1Gi

  # Defer control of security configurations to OpenShift
  podSecurityContext:
    enabled: false
  containerSecurityContext:
    enabled: false
  volumePermissions:
    enabled: false

# pfcon: ChRIS compute resource
#####################

pfcon:
  enabled: true

  name: "NERC"
  description: "New England Research Cloud - OpenShift (in-network, RWO volume)"
  replicaCount: 1
  podAnnotations: {}

  service:
    type: ClusterIP
    port: 5005

  # Storage space for CUBE files should be configured here.
  # It is recommended to allocate as much space as possible for CUBE files.
  storage:
    size: 200Gi
    accessModes: [ "ReadWriteOnce" ]

  # workaround for RWO volumes
  nodeSelector:
    kubernetes.io/hostname: wrk-13

  pfcon:
    resources:
      limits:
        cpu: 600m
        memory: 2288Mi
      requests:
        cpu: 600m
        memory: 2288Mi

    workers: 4
    workerTimeout: 3600

    # pfcon configuration
    # Recommended to keep as-is
    config:
      innetwork: true
      storageEnv: filesystem

  pman:
    # It is unnecessary to increase pman's resources to above the minimum because
    # pman doesn't do anything besides sending and receiving HTTP requests.
    resources:
      limits:
        cpu: 400m
        memory: 1Gi
      requests:
        cpu: 400m
        memory: 1Gi

    workers: 4
    workerTimeout: 30

    # pman configuration
    # https://github.com/fnndsc/pman#environment-variables
    config:
      JOB_LABELS: chrisproject.org/job=plugininstance,chrisproject.org/instance=cube1
      ENABLE_HOME_WORKAROUND: "yes"
      REMOVE_JOBS: "yes"
      IGNORE_LIMITS: "no"
      NODE_SELECTOR: "kubernetes.io/hostname=wrk-13"  # must match pfcon.nodeSelector

    # Should be disabled on OpenShift.
    setSecurityContext: false


# pfdcm: ChRIS PACS connector
#####################

pfdcm:
  enabled: true
  image:
    repository: ghcr.io/fnndsc/pfdcm
    pullPolicy: IfNotPresent
    tag: "3.1.22"
  podAnnotations: {}
  service:
    enabled: true
    type: ClusterIP
    port: 4005
  # OpenShift route
  route:
    enabled: true
    host: pfdcm.apps.shift.nerc.mghpcc.org
    tls:
      termination: edge
      insecureEdgeTerminationPolicy: Redirect
      destinationCACertificate: ''
  maxWorkers: 2
  resources:
    limits:
      cpu: 1
      memory: 3814Mi
    requests:
      cpu: 1
      memory: 3814Mi

  # DICOM Application Entity Title
  aet: "ChRIS"

  # DICOM listener for pfdcm. Enabled when pfdcm is enabled.
  listener:
    image:
      repository: ghcr.io/fnndsc/oxidicom
      pullPolicy: IfNotPresent
      tag: "1.0.0"
    podAnnotations: {}
    # The PACS server must be configured to push to this service.
    # If using Orthanc, the Helm chart will help you validate your
    # configuration of Orthanc's modailities to include this service.
    service:
      type: ClusterIP
      port: 11113
    replicas: 1
    ## manual configuration of OpenTelemetry
    env:
      - name: OTEL_RESOURCE_ATTRIBUTES
        value: service.name=oxidicom
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://otel-collector-collector:4318
    config:
      ## number of times 
      httpRetries: 3

      ## number of DICOM listener threads
      listenerThreads: 8

      ## number of threads to use for pushing files to CUBE
      pusherThreads: 8

      ## verbose logging
      # verbose: true

      ## strictPduLength, uncompressedOnly, and maxPduLength are strange DICOM
      ## options which you probably want to leave as their default values.
      # strictPduLength: true
      # uncompressedOnly: true
      # maxPduLength: 16384

      ## Addresses of the PACS pushing to us. Used for looking up the NumberOfSeriesRelatedInstances.
      ## Do not specify a value for pacsAddress if you are using the Orthanc sub-chart.
      # pacsAddress: pacs.server.local:4242
    resources:
      # It's written in Rust!
      # with 16 threads, CPU usage peaks at 120m and memory usage peaks at 1.3 GiB
      limits:
        cpu: 500m
        memory: 1907Mi
      requests:
        cpu: 500m
        memory: 1907Mi

# PACS server
orthanc:
  enabled: true
  podAnnotations: {}
  # Orthanc HTTP API and web app
  service:
    enabled: true
    type: ClusterIP
    port: 8042
  # PACS server
  dicomService:
    enabled: true
    type: ClusterIP
    port: 4242
  resources:
    limits:
      cpu: 1
      memory: 3814Mi
    requests:
      cpu: 1
      memory: 3814Mi
  config:
    # The logical name of this instance of Orthanc. This one is
    # displayed in Orthanc Explorer and at the URI "/system".
    # must be fewer than 20 characters, see https://github.com/FNNDSC/ChRIS_ultron_backEnd/issues/533
    # N.B. Sandip's plugins like pl-exec break if the name contains spaces.
    name: "NERC_Orthanc"
    # Enable the transparent compression of the DICOM instances
    storageCompression: false
    # Action to take when the maximum storage is reached.
    # By default, the patients are recycled ("Recycle" mode).
    # In "Reject" mode, the sender will receive a 0xA700 DIMSE status code
    # if the instance was sent through C-Store, a 507 HTTP status code
    # if using the REST API and a 0xA700 Failure reason when using
    # DicomWeb Stow-RS 
    # Allowed values: "Recycle", "Reject"
    # (new in Orthanc 1.11.2)
    maximumStorageMode: Reject
    # Maximum size of the storage cache in MB.  The storage cache
    # is stored in RAM and contains a copy of recently accessed
    # files (written or read).  A value of "0" indicates the cache
    # is disabled.  (new in Orthanc 1.10.0)
    maximumStorageCacheSize: 0

    # The DICOM Application Entity Title
    dicomAet: "ORTHANC"
    # Check whether the called AET corresponds during a DICOM request
    dicomCheckCalledAet: false

    # The default encoding that is assumed for DICOM files without
    # "SpecificCharacterSet" DICOM tag, and that is used when answering
    # C-Find requests (including worklists). The allowed values are
    # "Ascii", "Utf8", "Latin1", "Latin2", "Latin3", "Latin4",
    # "Latin5", "Cyrillic", "Windows1251", "Arabic", "Greek", "Hebrew",
    # "Thai", "Japanese", and "Chinese".
    defaultEncoding: "Latin1"

    # Set the timeout (in seconds) after which the DICOM associations
    # are closed by the Orthanc SCP (server) if no further DIMSE
    # command is received from the SCU (client).
    dicomScpTimeout: 30

    # The timeout (in seconds) after which the DICOM associations are
    # considered as closed by the Orthanc SCU (client) if the remote
    # DICOM SCP (server) does not answer.
    dicomScuTimeout: 10

    # Whether or not the password protection is enabled
    AuthenticationEnabled: true

    # The list of the registered users. Because Orthanc uses HTTP
    # Basic Authentication, the passwords are stored as plain text.
    # This MUST be set from the apply.sh script
    registeredUsers: {}

    # The list of the known DICOM modalities
    #
    # A fourth parameter is available to enable patches for a
    # specific PACS manufacturer. The allowed values are currently
    # "Generic" (default value), "StoreScp" (storescp tool from
    # DCMTK), "ClearCanvas", "MedInria", "Dcm4Chee", "SyngoVia",
    # "AgfaImpax" (Agfa IMPAX), "EFilm2" (eFilm version 2), and
    # "Vitrea". This parameter is case-sensitive.
    dicomModalities:
      # !!!IMPORTANT!!!
      # To use in combination with pfdcm, you MUST define a modality for
      # `.Values.pfdcm.aet`
      "ChRIS": [ "ChRIS", "cube1-oxidicom", 11113 ]

    # Whether Orthanc monitors its metrics (new in Orthanc 1.5.4). If
    # set to "true", the metrics can be retrieved at
    # "/tools/metrics-prometheus" formetted using the Prometheus
    # text-based exposition format.
    metricsEnabled: true

  ohif:
    enabled: true

  persistence:
    storage:
      size: 36Gi
      accessModes: [ ReadWriteOnce ]
    index:
      size: 4Gi
      accessModes: [ ReadWriteOnce ]
